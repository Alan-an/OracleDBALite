# OracleDBALite
Application: DBALite Oracle Database Performance Summary App  Application Purpose:  Provide Oracle host and database performance info suitable for non-dbas.  Target users are Non-dba performance engineers, testers, prod support staff and application team members who want to proactively and reactively monitor their databases.  Licensing: Because this App queries the dba_hist_sqlstat AWR data, a license must exist for the Oracle Diagnostic Pack.  Most facilities running Oracle databases have this license.  Application Basic Structure: Four stored procedures run in the Oracle database.  They read performance data tables and write it out to datafiles which are consumed by Splunk.  Oracle Scheduler jobs execute the stored procedures at configurable intervals.  The app also uses the Splunk Add-on for Unix and Linux to get host metrics.   Dependencies: Splunk Add-on for Unix and Linux  (http://docs.splunk.com/Documentation/UnixAddOn/latest/User/InstalltheSplunkAdd-onforUnixandLinux) Stored procedures and scheduler jobs running in Oracle Database 11.1 or higher (procedures scripts included in the setup files.)  Index creation: Splunk Add-on For Unix and Linux will create the 'unix_metrics' index. This DBALite app will create the 'database' index.  Sourcetypes: om:oracle:locks -- snapshot information about blocking locks om:oracle:memory -- Oracle sga and pga memory statistics om:oracle:osstat -- Operating System stats from v$osstat table om:oracle:sql -- top resource consuming sqls from dba_hist_sqlstat om:oracle:sqltext -- sqltext for the top resource consuming sqls om:oracle:sysevent -- wait event information om:oracle:sysstat -- performance statistics from v$sysstat table  Installation:  Oracle Setup:  Copy all the sql scripts from the Oracle_Performance_Summary_For_Splunk/bin directory to your database server or run them in SQL Developer or other tool. Connect to your database. As sysdba, create the splunk sch_spl user.  (Sysdba is required for this one script in order to grant privileges on DBMS_LOCK and UTL_FILE: @cr_sch_spl.sql  Create a unix directory where you want Oracle to write the output files.  Splunk will pick up the data from these output files created by the stored procedures.  If the owner of the directory is not the ORACLE user, then make the ORACLE user a member of the Unix group for the directory so that Oracle can write to the directory.  Make the permissions on the directory 774.  Note: For a RAC database, just create the directory on one node.  The app is not elaborate enough to provide failover capabilities, so in case of an outage of its node, the data would just not be written until the node came back online.    Create an Oracle Directory called 'DIR_SPLUNK' using the above unix directory. Example: CREATE DIRECTORY dir_splunk as '/u01/perf/dbdashboard/data'; grant read,write  on directory dir_splunk to sch_spl;  As the splunk user SCH_SPL, create the stored procedures and scheduler jobs that will run them: @cr_procs_and_jobs.sql  After 10 minutes, check the data files to confirm there is data being written to them.  These data files should exist: dbd_locks.txt dbd_memory.txt dbd_osstat.txt dbd_sysevents.txt dbd_sysstat.txt dbd_top_sql_text.txt dbd_top_sql.txt  To check the scheduler jobs, as SCH_SPL user, execute: 'SELECT job_name, actual_start_date, status, additional_info from user_scheduler_job_run_details order by actual_start_date;'        
